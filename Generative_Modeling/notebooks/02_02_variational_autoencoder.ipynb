{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569f2b06-f7af-45ca-a87e-ae67d3a1c819",
   "metadata": {},
   "source": [
    "### Multivariate Normal Distribution \n",
    "\n",
    "A Gaussian distribution is a probability distribution that is characterized by a distinctive bell curve shape and is defined by the mean and the variance. \n",
    "\n",
    "A multivariate standard normal distribution is a multivariate distribution with a zero-valued mean vector and identity covariance matrix which means that the distribution is independent in each dimensions. \n",
    "\n",
    "- Variational autoencoders assume that there is no correlation between dimensions in the latent space.Here, the encoder will take each input image and encode it to two vectors that together define a multivariate normal distribution in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9180255-b58c-427e-87d5-0e20671399ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 06:36:09.082926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 06:36:09.152322: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-13 06:36:09.172938: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-13 06:36:09.510314: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-13 06:36:09.510351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-13 06:36:09.510355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 06:36:10.060145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.078619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.078719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.079233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 06:36:10.080511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.080614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.080685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.379356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.379491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.379571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-13 06:36:10.379645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14074 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "from tensorflow.keras import layers,models,datasets,callbacks\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from utils import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbb528d-721f-4be2-818a-66f882cc2c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32 \n",
    "BATCH_SIZE = 100 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "EMBEDDING_DIM = 2 \n",
    "EPOCHS = 5 \n",
    "BETA = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9b289c-d319-4083-ad48-0562d7f8f118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the data \n",
    "(x_train,y_train), (x_test,y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bfe3e0-ae54-4d2c-a320-0c18bb7c8721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprocess the data \n",
    "def preprocess(imgs):\n",
    "    \"\"\"\n",
    "    Normalize and reshape the images\n",
    "    \"\"\"\n",
    "    imgs = imgs.astype(\"float32\")/255.0\n",
    "    imgs = np.pad(imgs,((0,0),(2,2),(2,2)),constant_values=0.0)\n",
    "    imgs = np.expand_dims(imgs,-1)\n",
    "    return imgs\n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a59e3-4bed-4d69-875c-ee50336eb898",
   "metadata": {},
   "source": [
    "### Build the variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16359c63-d3af-4f2d-83ba-24ca917a2db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self,inputs):\n",
    "        z_mean, z_log_var = inputs \n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch,dim))\n",
    "        return z_mean + tf.exp(0.5*z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca31713b-9fbd-408f-8b7d-5ccc8429d026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 32)   320         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     18496       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 128)    73856       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2048)         0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            4098        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            4098        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " sampling_1 (Sampling)          (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100,868\n",
      "Trainable params: 100,868\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(\n",
    "    shape=(IMAGE_SIZE, IMAGE_SIZE, 1), name=\"encoder_input\"\n",
    ")\n",
    "x = layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(\n",
    "    encoder_input\n",
    ")\n",
    "x = layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "shape_before_flattening = K.int_shape(x)[1:]  # the decoder will need this!\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "z_mean = layers.Dense(EMBEDDING_DIM, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(EMBEDDING_DIM, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfa0887-2511-4a55-bc9e-8e040e9b73ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              6144      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        147584    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 64)       73792     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " decoder_output (Conv2D)     (None, 32, 32, 1)         289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 246,273\n",
      "Trainable params: 246,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Decoder \n",
    "\n",
    "decoder_input = layers.Input(shape=(EMBEDDING_DIM,),name=\"decoder_input\")\n",
    "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    128,(3,3),strides=2, activation=\"relu\",padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    64,(3,3),strides=2,activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32,(3,3),strides=2,activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "decoder_output = layers.Conv2D(\n",
    "    1,\n",
    "    (3,3),\n",
    "    strides=1,\n",
    "    activation=\"sigmoid\",\n",
    "    padding=\"same\",\n",
    "    name=\"decoder_output\",)(x)\n",
    "\n",
    "decoder = models.Model(decoder_input,decoder_output)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc121cb-6a1b-4353-82a7-fcee347c4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(models.Model):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super(VAE,self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ] \n",
    "    \n",
    "    def call(self,inputs):\n",
    "        \"\"\"\n",
    "        Call the model on particular input \n",
    "        \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative_modeling",
   "language": "python",
   "name": "generative_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
